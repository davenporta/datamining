{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "from nltk.util import ngrams\n",
    "import re\n",
    "import nltk\n",
    "from gutenberg.cleanup import strip_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#book parameters\n",
    "isGut = True\n",
    "book = \"data/donquixote_gut.txt\"\n",
    "stop_additions = [\"said\", \"say\", \"replied\", \"del\", \"de\", \"la\", \"us\"] #dq crap words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alexh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\alexh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "download('stopwords')\n",
    "stopwords_list = stopwords.words('english')\n",
    "        \n",
    "stopwords_list += [\"thou\",\"wilt\",\"hast\",\"thee\",\"thy\"] #common old english\n",
    "stopwords_list += stop_additions #book specific words\n",
    "#print(stopwords_list)\n",
    "\n",
    "download('wordnet')\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "\n",
    "def lexical_diversity(work):\n",
    "    return len(set(work)) / len(work)\n",
    "\n",
    "def preprocess(sentence):\n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence.lower())\n",
    "    filtered_words = [w for w in tokens if not w in stopwords_list]\n",
    "    return filtered_words\n",
    "\n",
    "with open(book, \"r\") as book_text:\n",
    "    forest = book_text.read()\n",
    "\n",
    "if isGut: #remove project gutenberg headers and license\n",
    "    forest = strip_headers(forest)\n",
    "\n",
    "tokens = preprocess(forest)\n",
    "lem = [wnl.lemmatize(t) for t in tokens]\n",
    "\n",
    "text = nltk.Text(lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('quixote', 2322),\n",
       " ('sancho', 2205),\n",
       " ('one', 1725),\n",
       " ('would', 1251),\n",
       " ('knight', 896),\n",
       " ('good', 892),\n",
       " ('may', 842),\n",
       " ('know', 810),\n",
       " ('see', 790),\n",
       " ('time', 772),\n",
       " ('come', 771),\n",
       " ('without', 715),\n",
       " ('well', 714),\n",
       " ('made', 688),\n",
       " ('make', 686),\n",
       " ('could', 680),\n",
       " ('upon', 669),\n",
       " ('great', 663),\n",
       " ('let', 654),\n",
       " ('master', 635),\n",
       " ('give', 623),\n",
       " ('go', 618),\n",
       " ('like', 596),\n",
       " ('take', 594),\n",
       " ('though', 567),\n",
       " ('day', 550),\n",
       " ('worship', 548),\n",
       " ('god', 532),\n",
       " ('hand', 532),\n",
       " ('lady', 524),\n",
       " ('two', 521),\n",
       " ('way', 516),\n",
       " ('senor', 511),\n",
       " ('must', 505),\n",
       " ('came', 497),\n",
       " ('tell', 487),\n",
       " ('man', 484),\n",
       " ('word', 457),\n",
       " ('thing', 442),\n",
       " ('much', 440),\n",
       " ('life', 436),\n",
       " ('shall', 425),\n",
       " ('might', 410),\n",
       " ('world', 402),\n",
       " ('many', 377),\n",
       " ('never', 371),\n",
       " ('love', 365),\n",
       " ('little', 351),\n",
       " ('even', 350),\n",
       " ('heart', 348),\n",
       " ('another', 348),\n",
       " ('saw', 341),\n",
       " ('first', 339),\n",
       " ('eye', 332),\n",
       " ('name', 326),\n",
       " ('found', 323),\n",
       " ('put', 319),\n",
       " ('left', 318),\n",
       " ('head', 317),\n",
       " ('told', 317),\n",
       " ('friend', 317),\n",
       " ('book', 313),\n",
       " ('squire', 312),\n",
       " ('took', 312),\n",
       " ('arm', 311),\n",
       " ('heard', 311),\n",
       " ('nothing', 308),\n",
       " ('curate', 307),\n",
       " ('errant', 298),\n",
       " ('adventure', 298),\n",
       " ('panza', 294),\n",
       " ('dulcinea', 294),\n",
       " ('seen', 288),\n",
       " ('going', 288),\n",
       " ('chapter', 288),\n",
       " ('gave', 287),\n",
       " ('went', 286),\n",
       " ('end', 283),\n",
       " ('house', 280),\n",
       " ('father', 279),\n",
       " ('mean', 274),\n",
       " ('asked', 273),\n",
       " ('art', 272),\n",
       " ('thought', 272),\n",
       " ('truth', 270),\n",
       " ('mind', 266),\n",
       " ('three', 265),\n",
       " ('saying', 265),\n",
       " ('place', 262),\n",
       " ('find', 262),\n",
       " ('back', 260),\n",
       " ('called', 257),\n",
       " ('foot', 255),\n",
       " ('gentleman', 255),\n",
       " ('heaven', 254),\n",
       " ('duke', 253),\n",
       " ('look', 249),\n",
       " ('long', 248),\n",
       " ('leave', 246),\n",
       " ('ever', 244)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist(text).most_common(100)\n",
    "#text.collocations(30)\n",
    "#nltk.FreqDist(ngrams(text, 3)).most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [datamining]",
   "language": "python",
   "name": "Python [datamining]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
