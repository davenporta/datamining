{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Data IIb: Building a tweet classifier\n",
    "\n",
    "Name: Alex Davenport\n",
    "\n",
    "In this project, you'll finish off all the work that we've done so far, and build a collection of classifiers that \n",
    "\n",
    "## 1: Reshaping your code into classes\n",
    "\n",
    "At this point, you should have a solid understanding of text preprocessing, and the Naive Bayes algorithm.  Take the code from your previous projects, and consolidate it into two Python classes: \n",
    "\n",
    "* `TextPreprocessor`: Given a Pandas series of tweets (with punctuation, links, and other garbage), perform all the preprocessing necessary to construct a Pandas dataframe of vectorized tweets.  It should have some keyword arguments (set to reasonable defaults) that include all of the choices that you might make regarding text processing.  Here's an example, taken from our class worksheet:\n",
    "    \n",
    "    ```\n",
    "    >>> df = pd.DataFrame({\"Tweets\":[\"Trick or Treat!\",\n",
    "                                     \"One to Two Guesses\",\n",
    "                                     \"Try this one weird trick!\",\n",
    "                                     \"That's weird, you might guess\",\n",
    "                                     \"Can you guess these 10 health tricks?\"]})\n",
    "    >>> vectorized_tweets = TextProcessor(df, N=1000)\n",
    "    >>> vectorized_tweets\n",
    "    ```\n",
    "    \n",
    "|      | \"one\" | \"weird\" | \"trick\" | \"guess\" |\n",
    "|------|------|------|------|------|\n",
    "|   \"Trick or Treat!\"  |  0   |  0   |  1   |  0    |\n",
    "| \"One to Two Guesses\"  |   1  |   0  |  0   |  1    |\n",
    "| \"Try this one weird trick!\"   |   1  |  1   |  1   |   0   |\n",
    "| \"That's weird, you might guess\"   |  0   |  1   |  0   |  1    |\n",
    "| \"Can you guess these 10 health tricks?\"   |   0  |  0   |  1   |  1 |\n",
    "    \n",
    "* `NaiveBayes`: Given a Pandas Dataframe of vectorized tweets (the output of your `TextPreprocessor` class), train a Naive Bayes classifier, which can then be used to classify tweets it hasn't seen before.  \n",
    "\n",
    "    ```\n",
    "    >>> model = NaiveBayes()\n",
    "    >>> model.fit(vectorized_tweets, y)      // y is the column of 1's and 0's, as usual\n",
    "    >>> model.predict(\"Man, @nicholaszufelt is such a great teacher! #brownnoseforlife\")\n",
    "    1\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "#from sklearn.datasets import make_circles, make_moons, make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from math import *\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "fivethiryeight_colors = {\"blue\": \"#30a2da\", \n",
    "                         \"red\": \"#fc4f30\", \n",
    "                         \"green\": \"#e5ae38\", \n",
    "                         \"yellow\": \"#6d904f\", \n",
    "                         \"gray\": \"#8b8b8b\"}\n",
    "fivethirtyeight_rb = [\"#30a2da\", \"#fc4f30\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english') + [\"https\",\"http\",\"co\",\"amp\",\"rt\",\"â\",\"ð\",\"¾ð\",\"â¦\",\"ï\",\"½\",\"½ï\",\"¾\",\"wâ\",\"ð¤â¾\",\"www\"]\n",
    "\n",
    "#so elegant (i <3 nltk)\n",
    "#this basically is the first lab in like 6 lines\n",
    "stemmer = PorterStemmer() #initialize stemmer\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+') #initialize tokenizer\n",
    "ttk = nltk.tokenize.casual.TweetTokenizer(preserve_case=False, strip_handles=True)\n",
    "\n",
    "def preprocess(string):\n",
    "    handleless = \" \".join(ttk.tokenize(string))\n",
    "    tokens = tokenizer.tokenize(handleless) #tokenize, make lowercase, create list\n",
    "    filtered_words = [stemmer.stem(w) for w in tokens if not w in stopwords_list and len(w)>=3] #remove stopwords\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self, dataset, n=1000):\n",
    "        self.tweets = dataset \n",
    "        \n",
    "        #stem everything\n",
    "        self.tweets[\"stemmed\"] = self.tweets[\"text\"].apply(preprocess)\n",
    "\n",
    "        #n most common positive words\n",
    "        yay = self.tweets[self.tweets[\"sentiment\"] == 1].copy()\n",
    "        good_words = []\n",
    "        for tweet in yay[\"stemmed\"]:\n",
    "            good_words += set(tweet)\n",
    "        best = Counter(good_words).most_common(n)\n",
    "        \n",
    "        #only use words in common list\n",
    "        pos_features = [i[0] for i in best]\n",
    "        self.com_check = lambda tweet: set([word for word in tweet if word in pos_features])\n",
    "        self.tweets[\"stemmed\"] = self.tweets[\"stemmed\"].apply(self.com_check)\n",
    "        \n",
    "        #outputs\n",
    "        self.indicators = self.tweets['stemmed'].str.join(sep=' ').str.get_dummies(sep=' ')\n",
    "        self.vec_with_text = pd.concat([self.tweets[\"text\"],self.indicators], axis=1)\n",
    "        \n",
    "    def nb_prep(self, text):\n",
    "        nb_parsed = [word for word in preprocess(text) if word in list(self.indicators.columns)]\n",
    "        return nb_parsed\n",
    "    \n",
    "    def test_process(self, text):\n",
    "        parsed = self.com_check(preprocess(text))\n",
    "        #print(parsed)\n",
    "        names = list(self.indicators.columns)\n",
    "        data = pd.DataFrame(np.zeros((1,len(names))), columns=names)\n",
    "        #print(data)\n",
    "        for i in names:\n",
    "            if i in parsed:\n",
    "                #print(names[i])\n",
    "                data[i] = 1\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__ (self):\n",
    "        self.p1 = None\n",
    "        self.p0 = None\n",
    "        self.pos = None\n",
    "        self.neg = None\n",
    "        \n",
    "        \n",
    "    def fit(self, a, b):\n",
    "        #fit_data = pd.concat([a,b], axis=1)\n",
    "        #print(b)\n",
    "        self.pos = a[b == 1]\n",
    "        self.neg = a[b == 0]\n",
    "        \n",
    "        plen = len(self.pos)\n",
    "        nlen = len(self.neg)\n",
    "        total_len = plen + nlen\n",
    "        \n",
    "        self.p1 = plen/total_len\n",
    "        self.p0 = nlen/total_len\n",
    "        \n",
    "        self.pos = (self.pos.sum(axis=0)+1)/plen\n",
    "        self.neg = (self.neg.sum(axis=0)+1)/nlen\n",
    "    \n",
    "    def multi(self, l):\n",
    "        up = self.p1\n",
    "        down = self.p0\n",
    "        for word in l:\n",
    "            up *= self.pos[word]\n",
    "            down *= self.neg[word]\n",
    "        return [down, up]\n",
    "    \n",
    "    def predict(self, text):\n",
    "        probs = []\n",
    "        if isinstance(text, list):\n",
    "            probs.append(self.multi(text))\n",
    "        else:\n",
    "            for item in text:\n",
    "                probs.append(self.multi(item))\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Train-Test split \n",
    "\n",
    "Now, before you build your model, you need to construct some datasets to try out.  Fortunately, we've been working on building one!  You can download `tweets_class.txt` from Canvas.  It's a `.txt`, not a `.csv`, because tweets have a lot of commas in them, and that messed with Pandas `read_csv` method.  So `tweets_class.txt` is a tab-delimited dataset.  You'll need to change the delimiter for `read_csv`.  I also found that including the keyword `encoding='ISO-8859-1'` helped a ton as well.\n",
    "\n",
    "Take the data, split off some amount of it as a **test dataset**.  This means that you don't give it to your model, but you run it through the model after training to test its accuracy on tweets it hasn't seen before.  How much to split off is a good question, and the numbers vary from 10% to 50%.  Both of those extremes I think are a little over-the-top, I would recommend about 20-30%.  The remaining dataset is called your **training dataset**.\n",
    "\n",
    "A quick google search allowed me to find the gigantic [Sentiment Analysis Dataset](http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip).  It's 150MB, consisting of 1.5 million tweets which have been labeled for sentiment.  You may be getting frustrated with me at this point: \"Why did we have to go label all those tweets when there's a huge dataset already?!\"  I have many answers to this, but the most important one is that all of these labeled tweets were labeled by someone else's model, so I didn't want you to work off of entirely computer-generated data (It's the same idea behind \"a copy of a copy of a copy...\".  Nonetheless, let's pad our dataset with it.  Here's a line I found useful for opening that massive dataset in pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1          0  is upset that he can't update his Facebook by ...\n",
       "2          0  @Kenichan I dived many times for the ball. Man...\n",
       "3          0    my whole body feels itchy and like its on fire \n",
       "4          0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fixer(val):\n",
    "    if val == 4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "mega_df = pd.read_csv(\"data/training.1600000.processed.noemoticon.csv\", error_bad_lines=False, encoding='ISO-8859-1', names=[\"sentiment\",\"id\",\"timestamp\",\"idk\",\"handle\",\"text\"])[[\"sentiment\",\"text\"]]\n",
    "mega_df = mega_df.loc[mega_df['sentiment'] != 2]\n",
    "mega_df[\"sentiment\"] = mega_df[\"sentiment\"].apply(fixer)\n",
    "\n",
    "mega_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Moving the Tesla announcement to Wednesday. Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>@markpinc @TeslaMotors thanks!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>@Reuters Umm...Autobahn?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>@vicentes obviously wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>@Cocoanetics @heiseonline Not actually based o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0        0.0  Moving the Tesla announcement to Wednesday. Ne...\n",
       "1        1.0                     @markpinc @TeslaMotors thanks!\n",
       "2        0.0                           @Reuters Umm...Autobahn?\n",
       "3        0.0                          @vicentes obviously wrong\n",
       "4        0.0  @Cocoanetics @heiseonline Not actually based o..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_df = pd.read_csv(\"data/tweets_class.txt\", sep=\"\\t\", encoding='ISO-8859-1', error_bad_lines=False).dropna().reset_index(drop=True)\n",
    "class_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add some number of these labeled tweets to your dataset.  How much is up to you, I might suggest some number of thousands, but less than 10 thousand (Though feel free to try more!).  Take them randomly from the dataframe, not from the top.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>The attack on the Orange County HQ @NCGOP offi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Half way there&amp;newline;#Believeland #Cubs #wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>RT @lifewithoutPB: Put on some #BadHombre for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Thank you Colorado Springs. If Im elected Pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>i would go a step further these are the two mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0        0.0  The attack on the Orange County HQ @NCGOP offi...\n",
       "1        1.0  Half way there&newline;#Believeland #Cubs #wor...\n",
       "2        0.0  RT @lifewithoutPB: Put on some #BadHombre for ...\n",
       "3        0.0  Thank you Colorado Springs. If Im elected Pres...\n",
       "4        0.0  i would go a step further these are the two mo..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_df = class_df.sample(len(class_df)).reset_index(drop=True)\n",
    "split = int(len(class_df)/4)\n",
    "test_df = class_df.ix[:split].copy()\n",
    "training_set = class_df.ix[split:].copy()\n",
    "\n",
    "SAMPLE_COUNT = 5000\n",
    "training_set = pd.concat([training_set, mega_df.sample(SAMPLE_COUNT)], axis=0, ignore_index=True)\n",
    "\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data = TextPreprocessor(training_set, n=300)\n",
    "X = training_data.indicators\n",
    "y = training_set[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Train and test your models\n",
    "\n",
    "Build both a Naive Bayes and a Logistic Regression classifier on your training dataset, and test them on your test dataset.  Which is better? What percent of positives and negatives do you have? How many false positives and false negatives do you have?  Interpret your results.  Is your model better or worse when you include the computer-generated data?  Add some bigrams to, and try changing your `N` in Naive Bayes, and try changing your `C` in Logistic Regression.  What's the best model? (This is why creating a robust class in part 1 will help you.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_binned_test = pd.concat(list(test_df[\"text\"].apply(training_data.test_process)), axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_mod = LogisticRegression()\n",
    "log_mod.fit(X,y)\n",
    "log_results = log_mod.predict(log_binned_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_binned_test = test_df[\"text\"].apply(training_data.nb_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def best(array):\n",
    "    out = []\n",
    "    for row in array:\n",
    "        if row[0] > row[1]:\n",
    "            out.append(0)\n",
    "        else:\n",
    "            out.append(1)\n",
    "    return np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_mod = NaiveBayes()\n",
    "nb_mod.fit(X,y)\n",
    "nb_results = best(nb_mod.predict(nb_binned_test)) #predict and make sure same data type as log_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[341 102]\n",
      " [172 240]]\n",
      "[[359  84]\n",
      " [181 231]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(test_df[\"sentiment\"],log_results))\n",
    "print(confusion_matrix(test_df[\"sentiment\"],nb_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the naive bayes classifier is marginally better. With an n of 500, the logistic has 274 falses and the NB has 265 falses. The NB classifier tends to prefer false negatives to false positives. This may be an artifact of an imbalance in the sentiments of the tweets. The Naive Bayes has a success rate of 69%. Pretty abysmal. Logistic is awful as well with 67.9%. I found that the data was better with computer generated data added. This indicates that out data probably is not very good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [datamining]",
   "language": "python",
   "name": "Python [datamining]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
