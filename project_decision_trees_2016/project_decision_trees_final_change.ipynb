{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Decision Trees\n",
    "\n",
    "## Machine Learning, Winter 2017\n",
    "\n",
    "### Name: Neel Shroff, Alex Davenport, Tony Tan, Gherardo Morona\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, you'll perform the following tasks:\n",
    "1. Construct a (Python) class `DecisionTree` which will serve as our first machine learning model.\n",
    "2. Test it out on multiple datasets.  If you've done the above correctly, this shouldn't be hard!\n",
    "3. Determine the effects of overfitting and attempt some solutions, discussing which seem to work best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Standard import statements:\n",
    "from itertools import combinations, chain\n",
    "from statistics import mean, median\n",
    "from operator import itemgetter\n",
    "from sklearn.datasets import make_blobs, load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, r2_score, precision_score, recall_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DecisionTree` Class\n",
    "\n",
    "Construct a `DecisionTree` class in the cell below.  It should support the standard scikit-learn API: \n",
    "\n",
    "```\n",
    ">>> X, y = <your_dataset>\n",
    ">>> model = DecisionTree() # potentially with some parameters, if needed\n",
    ">>> model.fit(X,y)\n",
    ">>> model.predict(<new_sample_vector>)\n",
    "1\n",
    ">>> # If the model predicted your sample vector to be in class 1.\n",
    "```\n",
    "\n",
    "Note that your `predict` function should support either single predictions or multiple predictions, though you can force the user to do single predictions as a 2d array (single-row \"multiple\" predictions) so you only have one implementation to write.  What I mean by this is `model.predict(X)` should work (without error) to create all predictions for `y`.\n",
    "\n",
    "You should construct some human-readable visualization of your model, simply from a printout.  This way you can tell if the model is being built the way you want.  The best way to do this is to implement the `__str__` method for your class.  Probably the easiest way to do this is to iterate through the tree in a \"depth-first\" fashion, and for each node, just print out some basic facts, like the number of elements in that node, or the indices of those elements in `X`, and the class assignment if it's a leaf node; also, make sure the indentation level of each node increases as its depth increases.  It might be helpful to have your nodes be more than just the bare minimum object (which would probably be a list of the indices of the rows in `X` for the items in your node).  To reiterate: this should NOT be a \"beautiful\" printout with lines like:\n",
    "```\n",
    "            root\n",
    "           /    \\\n",
    "     child1      child2 \n",
    "    /      \\    /      \\\n",
    "...\n",
    "```\n",
    "\n",
    "Because that would get awkward fast.  What I'm imagining is:\n",
    "\n",
    "```\n",
    "root: <root_info>\n",
    "  child1: <child1_info>\n",
    "    grandchild1: <grandchild1_info>\n",
    "      ...\n",
    "    grandchild1: <grandchild2_info>\n",
    "      ...\n",
    "  child2: <child2_info>\n",
    "    grandchild1: <grandchild1_info>\n",
    "    grandchild1: <grandchild2_info>\n",
    "```\n",
    "\n",
    "By implementing this in `__str__` for your class, this will be the printout when you run:\n",
    "\n",
    "```\n",
    "model = DecisionTree(<whatever_you_need_to_do_to_create_your_model>)\n",
    "model.fit(X,y)\n",
    "print(model)\n",
    "```\n",
    "\n",
    "Recall the algorithm for fitting a decision tree:\n",
    "1. Start with all your data samples in a single node.\n",
    "2. For a given node, determine if you want to split at that node or not.  For now, this should just be a check to see if the node is \"pure\", meaning it only contains one class.  If you do decide to split it further, compute all possible splits of your data (all possible depth-1 subtrees).  For categorical variables, this should look like generating all pairs of combinations of classes.  For continuous or ordinal variables, sort the entries in that column, and then all possible splits involve cutting off at values between adjacent entries.  That is, if the entries in my continuous column are `[2.01, 3.425, 8.67, 493.6]`, then I have three splits, which are \n",
    "\"$x_i\\leq 2.01$\", \"$x_i\\leq 3.425$\", \"$x_i\\leq 8.67$\".\n",
    "3. Compute the change in Gini Impurity for each split, and choose the split that has the largest gain in information (most pure nodes).  Recall that the Gini Impurity for a node is \n",
    "$$ I = 1 - \\sum_{\\text{each class}} \\left(\\frac{\\text{# of elements in that class}}{\\text{# of elements in the node}}\\right)^2$$\n",
    "So then you want to minimize $I_\\text{new_child1} + I_\\text{new_child2} - I_\\text{old}$; that is, choose the split with the largest value for that quantity (roughly interpretted as \"information gain\", though for the record the term \"information gain\" is used in a totally-synonymous-but-technically-different situation).\n",
    "4. Repeat until all nodes are pure.\n",
    "5. (Get the above working first, and then later:) prune the tree back to avoid overfitting your training data. (See below)\n",
    "\n",
    "Note that your (Python) class should work for multi-class datasets (where you're trying to predict a `y` that has more than two classes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Class\n",
    "\n",
    "Along with the `__init__` method, the class has 7 other methods:\n",
    " * `fit`: Creates the a model for the dataset.\n",
    " * `predict`: Responsible for predicting the classes for a list of predictions.\n",
    " * `calculate_gini`: Calculates the Gini impurity of the given node.\n",
    " * `find_best_split`: Finds best split.\n",
    " * `fitter`: Complements the fit method.\n",
    " * `show`: Helps implement the visual representation.\n",
    " * `__str__`: String representation of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    def __init__(self, x=None):\n",
    "        self.tree = x\n",
    "    \n",
    "    def fit(self, X, y, n=10):\n",
    "        # Inputs:\n",
    "        # n : the limit for the number of nodes the tree will have predictors/class are dataframes with same indexing\n",
    "        # X and y: dataframes\n",
    "        # Sets tree to a list with left node, right node, threshold, predictor, and count.\n",
    "        self.tree = self.fitter(X, y, n)\n",
    "        return\n",
    "    \n",
    "    def predict(self, X_predict):\n",
    "    # input: X_predict (which is a dataframe)\n",
    "    # returns a list with each item bui;ding the prediction for each row of the X_predict dataframe\n",
    "        class_predictions = []\n",
    "        node1 = self.tree\n",
    "        node = node1\n",
    "        for prediction in X_predict.iterrows():\n",
    "            row = prediction[1]\n",
    "            while len(node) > 1:\n",
    "                if row[node[2][0]] <= node[2][1]:\n",
    "                    node = node[0]\n",
    "                else:\n",
    "                    node = node[1]\n",
    "            class_predictions.append(node)\n",
    "            node = node1\n",
    "        return class_predictions\n",
    "    \n",
    "    def calculate_gini(self, P):\n",
    "        # Input: a list of classes, such as ['S', 'NS', 'NS', 'NS', 'S'] or [0,1,0,2,1,0] if 0,1,2 are the things\n",
    "        # that corresponds to an increasing list of some parameter that you want to split by.\n",
    "        # Returns: gini score.\n",
    "        # Used by: get_possible_splits().\n",
    "        classes = list(set(P))  # find all the classes\n",
    "        gini = 1\n",
    "        for i in classes:\n",
    "            gini -= (float(P.count(i)) / len(P)) ** 2\n",
    "        return gini\n",
    "\n",
    "    def find_best_split(self, node_x, node_y):\n",
    "        # Returns the best split (threshold).\n",
    "        gp = self.calculate_gini(list(node_y.values.flatten()))\n",
    "        poss_splits = []\n",
    "        for pred in node_x.columns:\n",
    "            set_list = list(node_x[pred].unique())\n",
    "            set_list.sort()\n",
    "            for t in set_list[:-1]:\n",
    "                downside = list(node_y[node_x[pred] <= t].values.flatten())\n",
    "                upside = list(node_y[node_x[pred] > t].values.flatten())\n",
    "                #print(list(downside))\n",
    "                #print(list(upside))\n",
    "                ig = gp - (\n",
    "                    (len(downside) / len(node_y)) * self.calculate_gini(downside)\n",
    "                    + (len(upside) / len(node_y)) * self.calculate_gini(upside))\n",
    "                poss_splits.append((pred, t, ig, gp))\n",
    "        try:\n",
    "            return max(poss_splits, key=itemgetter(2))\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def fitter(self, X, y, n, branch=True):\n",
    "        #print(\"Running fit\")\n",
    "        # Inputs:\n",
    "        # n : the limit for the number of nodes the tree will have predictors/class are dataframes with same indexing\n",
    "        # X and y: dataframes\n",
    "        # Returns: a list with left node, right node, threshold\n",
    "\n",
    "        if n == 0:\n",
    "            return list([y.value_counts().idxmax()])\n",
    "\n",
    "        n -= 1\n",
    "        node = [[], [], []]\n",
    "        tup = self.find_best_split(X, y)\n",
    "\n",
    "        if tup != None:\n",
    "            predictor, threshold, info_gain, gini = tup\n",
    "        else:\n",
    "            return list(y.unique())\n",
    "\n",
    "        if gini <= 0.0001:  # if the node is pure (gini impurity is 0), then stop\n",
    "            return list(y.unique())\n",
    "\n",
    "        node[0] = self.fitter(X[X[predictor] <= threshold], y[X[predictor] <= threshold], n=n, branch=True)\n",
    "        node[1] = self.fitter(X[X[predictor] > threshold], y[X[predictor] > threshold], n=n, branch=False)\n",
    "        node[2] = (predictor,threshold,len(y))\n",
    "\n",
    "        return node\n",
    "    \n",
    "    def show(self, tree, n=0):\n",
    "        # Used to create the visual representation of the tree.\n",
    "        spacing = \"\"\n",
    "        for i in range(n):\n",
    "            spacing += \"   \"\n",
    "        if n == 0:\n",
    "            spacing += \"root: \"\n",
    "        elif n == 1:\n",
    "            spacing += \"child: \"\n",
    "        elif n > 1:\n",
    "            spacing += \"grandchild^\" + str(n-1) + \": \"\n",
    "        if len(tree) == 3:\n",
    "            print(spacing, \"predictor:\", tree[2][0], \"| threshold:\", tree[2][1], \"| # elements:\", tree[2][2])\n",
    "            n += 1\n",
    "            self.show(tree[0], n)\n",
    "            self.show(tree[1], n)\n",
    "        else:\n",
    "            print(spacing, \"class of leaf:\", str(tree[0]))\n",
    "            return\n",
    "    \n",
    "    def __str__(self):\n",
    "        self.show(self.tree)\n",
    "        return \" \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test out your code, here's a simple dataset.  You could check it by hand if you need to debug.  You're trying to predict whether an animal is a mammal or not (the class label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = [[\"human\", \"warm-blooded\", \"yes\", \"no\", \"no\", \"yes\"],\n",
    "     [\"pigeon\", \"warm-blooded\", \"no\", \"no\", \"no\", \"no\"],\n",
    "     [\"elephant\", \"warm-blooded\", \"yes\", \"yes\", \"no\", \"yes\"],\n",
    "     [\"leopard shark\", \"cold-blooded\", \"yes\", \"no\", \"no\", \"no\"],\n",
    "     [\"turtle\", \"cold-blooded\", \"no\", \"yes\", \"no\", \"no\"],\n",
    "     [\"penguin\", \"cold-blooded\", \"no\", \"no\", \"no\", \"no\"],\n",
    "     [\"eel\", \"cold-blooded\", \"no\", \"no\", \"no\", \"no\"],\n",
    "     [\"dolphin\", \"warm-blooded\", \"yes\", \"no\", \"no\", \"yes\"],\n",
    "     [\"spiny anteater\", \"warm-blooded\", \"no\", \"yes\", \"yes\", \"yes\"],\n",
    "     [\"gila monster\", \"cold-blooded\", \"no\", \"yes\", \"yes\", \"no\"]]\n",
    "\n",
    "df = pd.DataFrame(X, columns = [\"Name\", \n",
    "                                \"Body Temperature\", \n",
    "                                \"Gives Birth\", \n",
    "                                \"Four-legged\", \n",
    "                                \"Hibernates\", \n",
    "                                \"Class Label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it out on multiple datasets\n",
    "\n",
    "Feel free to split these amongst your group mates, then consolodate it into one notebook.\n",
    "\n",
    "1. The dataset `X` above.\n",
    "\n",
    "2. To double check that your multi-class support is working, use the [iris dataset](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris).  Plot some decision boundaries of the classifier you make in all the pairs of dimensions in your scatter plots.\n",
    "\n",
    "3. Take a look at some of the [dataset constructors in scikit-learn](http://scikit-learn.org/stable/datasets/#sample-generators).  Pick one that will allow you to generate a dataset that has $\\geq 4$ features, and multiple classes ($\\geq 3$); but also make sure that when I run your code with some tweaked numbers from these, it will still work.\n",
    "\n",
    "4. Kaggle is a website which offers machine learning challenges to anyone with an interest in working on them, some of which have real prizes associated with them.  The [Titanic challenge](https://www.kaggle.com/c/titanic/data) is a tutorial challenge which has you attempting to predict whether someone did or did not die on board the Titanic, based on their criteria.  In order to download the dataset, you'll need to make an account, and agree to some scary-sounding agreement about not sharing their data with the world (to make their legal team happy).  Do only the minimum of data cleanup on it, trash the name column (unless you want to get really fancy), and fit a decision tree to the dataset.  Make sure to save some data for testing purposes.\n",
    "\n",
    "5. Add some classification metrics to your above models, like the `accuracy_score` and `confusion_matrix`.  Add additionally [Precision and Recall](https://en.wikipedia.org/wiki/Precision_and_recall), and explain what those are.\n",
    "\n",
    "6. For the dataset `noisy_dataset.csv`, available on Canvas in `Files`, plit the data into `test` and `train` sets, and then construct a family of decision trees with an increasing number of nodes, say from 3 up to something large (large enough that the test accuracy starts getting awful). Plot a pair of curves on the same axes: (# of nodes) vs. model accuracy (training and test).  Discuss which models make the best predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1\n",
    "This dataset classifies an animal as a mammal or a non-mammal. We are going to use this simple dataset to help us debug our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Body Temperature</th>\n",
       "      <th>Gives Birth</th>\n",
       "      <th>Four-legged</th>\n",
       "      <th>Hibernates</th>\n",
       "      <th>Class Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>warm-blooded</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pigeon</td>\n",
       "      <td>warm-blooded</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>elephant</td>\n",
       "      <td>warm-blooded</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leopard shark</td>\n",
       "      <td>cold-blooded</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>turtle</td>\n",
       "      <td>cold-blooded</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name Body Temperature Gives Birth Four-legged Hibernates  \\\n",
       "0          human     warm-blooded         yes          no         no   \n",
       "1         pigeon     warm-blooded          no          no         no   \n",
       "2       elephant     warm-blooded         yes         yes         no   \n",
       "3  leopard shark     cold-blooded         yes          no         no   \n",
       "4         turtle     cold-blooded          no         yes         no   \n",
       "\n",
       "  Class Label  \n",
       "0         yes  \n",
       "1          no  \n",
       "2         yes  \n",
       "3          no  \n",
       "4          no  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to binarize the categorical predictors in the dataframe. Four of the columns use \"yes\" or \"no\" as their values, while one of the columns use \"warm-blooded\" and \"cold-blooded.\" I am going to make \"yes\" and \"warm-blooded\" into a 1 and \"no\" and \"cold-blooded\" into a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Body Temperature</th>\n",
       "      <th>Gives Birth</th>\n",
       "      <th>Four-legged</th>\n",
       "      <th>Hibernates</th>\n",
       "      <th>Class Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pigeon</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>elephant</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leopard shark</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>turtle</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name  Body Temperature  Gives Birth  Four-legged  Hibernates  \\\n",
       "0          human                 1            1            0           0   \n",
       "1         pigeon                 1            0            0           0   \n",
       "2       elephant                 1            1            1           0   \n",
       "3  leopard shark                 0            1            0           0   \n",
       "4         turtle                 0            0            1           0   \n",
       "\n",
       "   Class Label  \n",
       "0            1  \n",
       "1            0  \n",
       "2            1  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def binarize(var):\n",
    "    if var == \"no\":\n",
    "        return 0\n",
    "    elif var == \"yes\":\n",
    "        return 1\n",
    "df[[\"Gives Birth\",\"Four-legged\",\"Hibernates\",\"Class Label\"]] = df[[\"Gives Birth\",\"Four-legged\",\"Hibernates\",\"Class Label\"]].applymap(binarize)\n",
    "body_temp = {\"warm-blooded\": 1, \"cold-blooded\": 0}\n",
    "df['Body Temperature'] = df['Body Temperature'].map(body_temp)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Now we need to split this into two datasets: an X dataset with all the predictors, and a y dataset with the response variable `Class Label.` `Name` will not be included in the X dataset because it will not currently help us with classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_mammal = df[df.columns.tolist()[1:len(df.columns) - 1]]\n",
    "y_mammal = df[\"Class Label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try fitting this dataset to our Decision Tree Class to see if the `fit` method and the `__str__` method works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root:  predictor: Body Temperature | threshold: 0 | # elements: 10\n",
      "   child:  class of leaf: 0\n",
      "   child:  predictor: Gives Birth | threshold: 0 | # elements: 5\n",
      "      grandchild^1:  predictor: Four-legged | threshold: 0 | # elements: 2\n",
      "         grandchild^2:  class of leaf: 0\n",
      "         grandchild^2:  class of leaf: 1\n",
      "      grandchild^1:  class of leaf: 1\n",
      " \n"
     ]
    }
   ],
   "source": [
    "one = Tree()\n",
    "one.fit(X_mammal, y_mammal)\n",
    "print(one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it works! Our visualization of the tree shows the predictor, the threshold, and the number of elements for each node. For the leaf nodes, it shows the class assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move on to dataset 2. This time I am going to load in the iris dataset using `load_iris()`. After creating the X and y datasets, I am going to use `train_test_split` to create a training dataset and a test dataset for both of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = load_iris()\n",
    "X_iris = pd.DataFrame(data=dataset['data'])\n",
    "X_iris.columns = dataset['feature_names']\n",
    "y_iris = pd.Series(data=dataset['target'])\n",
    "X_iris_train, X_iris_test, y_iris_train, y_iris_test = train_test_split(X_iris, y_iris, test_size=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now I need to fit these datasets to the Decision Tree Class and print out the visualization of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root:  predictor: petal length (cm) | threshold: 1.7 | # elements: 105\n",
      "   child:  class of leaf: 0\n",
      "   child:  predictor: petal width (cm) | threshold: 1.7 | # elements: 70\n",
      "      grandchild^1:  predictor: petal length (cm) | threshold: 4.9 | # elements: 38\n",
      "         grandchild^2:  predictor: petal width (cm) | threshold: 1.6 | # elements: 34\n",
      "            grandchild^3:  class of leaf: 1\n",
      "            grandchild^3:  class of leaf: 2\n",
      "         grandchild^2:  predictor: petal width (cm) | threshold: 1.6 | # elements: 4\n",
      "            grandchild^3:  class of leaf: 2\n",
      "            grandchild^3:  class of leaf: 1\n",
      "      grandchild^1:  class of leaf: 2\n",
      " \n"
     ]
    }
   ],
   "source": [
    "two = Tree()\n",
    "two.fit(X_iris_train, y_iris_train)\n",
    "print(two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to test the accuracy of our model by determining the accuracy score and the confusion matrix. I am also going to be finding the precision score and recall score.\n",
    "According to the sklearn documentation, `precision score` is a fraction that represents \"the number of true positives over the number of true positives plus the number of false positives,\" and the `recall score` is \"the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Accuracy Check\n",
    "def metrics(y_true, y_preds):\n",
    "    print(\"Confusion Matrix: \")\n",
    "    print(confusion_matrix(y_true,y_preds))\n",
    "    print()\n",
    "    print(\"Accuracy Score: \")\n",
    "    print(accuracy_score(y_true,y_preds))\n",
    "    print()\n",
    "    print(\"Precision Score: \")\n",
    "    print(precision_score(y_true,y_preds,average='macro'))\n",
    "    print(\"Recall Score: \")\n",
    "    print(recall_score(y_true,y_preds,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[13  2  0]\n",
      " [ 0 14  2]\n",
      " [ 0  0 14]]\n",
      "\n",
      "Accuracy Score: \n",
      "0.911111111111\n",
      "\n",
      "Precision Score: \n",
      "0.916666666667\n",
      "Recall Score: \n",
      "0.913888888889\n"
     ]
    }
   ],
   "source": [
    "iris_preds = two.predict(X_iris_test)\n",
    "metrics(y_iris_test, iris_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model seems to be pretty accurate. The accuracy score is about 93% and there are only 3 misclassified points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 3\n",
    "\n",
    "Now let's move on to dataset 3. This time I am going to create my own dataset using the `make_blobs` method in `sklearn.` I set `n_samples` to 150 to indicate that there should 150 data points. I set `n_features` to 5 to indicate that there will be 5 predictors. I set `centers` to 3 to indicate that there will be three different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X,y = make_blobs(n_samples = 150, n_features = 5, centers = 3)\n",
    "X_blob = pd.DataFrame(data=X)\n",
    "y_blob = pd.Series(data=y)\n",
    "X_blob_train, X_blob_test, y_blob_train, y_blob_test = train_test_split(X_blob, y_blob, test_size=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to before, I need to fit the data using the `fit` method in our class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root:  predictor: 0 | threshold: -4.77608777721 | # elements: 105\n",
      "   child:  class of leaf: 2\n",
      "   child:  predictor: 1 | threshold: -6.41077834214 | # elements: 68\n",
      "      grandchild^1:  class of leaf: 1\n",
      "      grandchild^1:  class of leaf: 0\n",
      " \n"
     ]
    }
   ],
   "source": [
    "three = Tree()\n",
    "three.fit(X_blob_train, y_blob_train)\n",
    "print(three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[16  0  0]\n",
      " [ 1 15  0]\n",
      " [ 0  0 13]]\n",
      "\n",
      "Accuracy Score: \n",
      "0.977777777778\n"
     ]
    }
   ],
   "source": [
    "blob_preds = three.predict(X_blob_test)\n",
    "metrics(y_blob_test, blob_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model also seems to be pretty accurate. The accuracy score is about 98% and there are only 1 misclassified points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 4\n",
    "This dataset is from an online challenge therefore there may be some missing data and other conveniences. Let's begin by importing the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic_train = pd.read_csv(\"train_titanic.csv\")\n",
    "df_titanic_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to delete `PassengerId` because my dataframe already has indexing. \n",
    "I am also going to delete `Name` because it is not very useful as a predictor. \n",
    "I am also going to delete `Cabin` because it is not a very useful predictor and there are many empty cells in the column.\n",
    "Lastly, I am going to delete `Ticket` because there is no consistent format to the values in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del df_titanic_train[\"PassengerId\"]\n",
    "del df_titanic_train[\"Name\"]\n",
    "del df_titanic_train[\"Cabin\"]\n",
    "del df_titanic_train[\"Ticket\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to binarize many of the columns in the dataframe.\n",
    "First I am going to change male and female in the `Sex` column to 1 and 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S' 'C' 'Q' nan]\n"
     ]
    }
   ],
   "source": [
    "gender_bin = {\"male\": 1, \"female\": 0}\n",
    "df_titanic_train['Sex'] = df_titanic_train['Sex'].map(gender_bin)\n",
    "print(df_titanic_train['Embarked'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Embarked` seems to have a few missing cells. Let's find them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex   Age  SibSp  Parch  Fare Embarked\n",
       "61          1       1    0  38.0      0      0  80.0      NaN\n",
       "829         1       1    0  62.0      0      0  80.0      NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic_train[df_titanic_train['Embarked'].isin(['S','C','Q']) == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are only two rows with missing values, I am going to delete both of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0         0       3    1  22.0      1      0   7.2500        S\n",
       "1         1       1    0  38.0      1      0  71.2833        C\n",
       "2         1       3    0  26.0      0      0   7.9250        S\n",
       "3         1       1    0  35.0      1      0  53.1000        S\n",
       "4         0       3    1  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic_train = df_titanic_train.drop(61)\n",
    "df_titanic_train = df_titanic_train.drop(829)\n",
    "df_titanic_train = df_titanic_train.reset_index(drop=True)\n",
    "df_titanic_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to binarize the `Embarked` column. I am going to make two columns for `is_southampton` and `is_cherbourg`. When both of these are 0, it will represent `is_queenstown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>is_southampton</th>\n",
       "      <th>is_cherbourg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  is_southampton  \\\n",
       "0         0       3    1  22.0      1      0   7.2500               1   \n",
       "1         1       1    0  38.0      1      0  71.2833               0   \n",
       "2         1       3    0  26.0      0      0   7.9250               1   \n",
       "3         1       1    0  35.0      1      0  53.1000               1   \n",
       "4         0       3    1  35.0      0      0   8.0500               1   \n",
       "\n",
       "   is_cherbourg  \n",
       "0             0  \n",
       "1             1  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def change_embark(dataframe):\n",
    "    cherbourg = []\n",
    "    southampton = []\n",
    "    for x in dataframe['Embarked']:\n",
    "        if x == 'S':\n",
    "            southampton.append(1)\n",
    "            cherbourg.append(0)\n",
    "        if x == 'C':\n",
    "            southampton.append(0)\n",
    "            cherbourg.append(1)\n",
    "        if x == 'Q':\n",
    "            southampton.append(0)\n",
    "            cherbourg.append(0)\n",
    "    dataframe['is_southampton'] = southampton\n",
    "    dataframe['is_cherbourg'] = cherbourg\n",
    "\n",
    "change_embark(df_titanic_train)\n",
    "del df_titanic_train[\"Embarked\"]\n",
    "df_titanic_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am going to check the `Age` column for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>is_southampton</th>\n",
       "      <th>is_cherbourg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21.6792</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.3125</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.6000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.6958</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.9500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.7000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>89.1042</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex  Age  SibSp  Parch      Fare  is_southampton  \\\n",
       "5           0       3    1  NaN      0      0    8.4583               0   \n",
       "17          1       2    1  NaN      0      0   13.0000               1   \n",
       "19          1       3    0  NaN      0      0    7.2250               0   \n",
       "26          0       3    1  NaN      0      0    7.2250               0   \n",
       "28          1       3    0  NaN      0      0    7.8792               0   \n",
       "29          0       3    1  NaN      0      0    7.8958               1   \n",
       "31          1       1    0  NaN      1      0  146.5208               0   \n",
       "32          1       3    0  NaN      0      0    7.7500               0   \n",
       "36          1       3    1  NaN      0      0    7.2292               0   \n",
       "42          0       3    1  NaN      0      0    7.8958               0   \n",
       "45          0       3    1  NaN      0      0    8.0500               1   \n",
       "46          0       3    1  NaN      1      0   15.5000               0   \n",
       "47          1       3    0  NaN      0      0    7.7500               0   \n",
       "48          0       3    1  NaN      2      0   21.6792               0   \n",
       "55          1       1    1  NaN      0      0   35.5000               1   \n",
       "63          0       1    1  NaN      0      0   27.7208               0   \n",
       "64          1       3    1  NaN      1      1   15.2458               0   \n",
       "75          0       3    1  NaN      0      0    7.8958               1   \n",
       "76          0       3    1  NaN      0      0    8.0500               1   \n",
       "81          1       3    0  NaN      0      0    7.7875               0   \n",
       "86          0       3    1  NaN      0      0    8.0500               1   \n",
       "94          0       3    1  NaN      0      0    8.0500               1   \n",
       "100         0       3    1  NaN      0      0    7.8958               1   \n",
       "106         1       3    1  NaN      0      0    7.7750               1   \n",
       "108         1       3    0  NaN      1      0   24.1500               0   \n",
       "120         0       3    1  NaN      0      0    8.0500               1   \n",
       "125         0       3    1  NaN      0      0    7.7500               0   \n",
       "127         1       3    0  NaN      1      1   22.3583               0   \n",
       "139         0       3    0  NaN      0      2   15.2458               0   \n",
       "153         0       3    1  NaN      0      0    7.3125               1   \n",
       "..        ...     ...  ...  ...    ...    ...       ...             ...   \n",
       "717         0       3    1  NaN      0      0   15.5000               0   \n",
       "726         1       3    0  NaN      0      0    7.7375               0   \n",
       "731         0       2    1  NaN      0      0    0.0000               1   \n",
       "737         0       3    1  NaN      0      0    7.8958               1   \n",
       "738         0       3    1  NaN      0      0    7.8958               1   \n",
       "739         1       1    1  NaN      0      0   30.0000               1   \n",
       "759         0       3    1  NaN      0      0   14.5000               1   \n",
       "765         0       1    1  NaN      0      0   39.6000               0   \n",
       "767         0       3    1  NaN      1      0   24.1500               0   \n",
       "772         0       3    1  NaN      0      0    7.2250               0   \n",
       "775         0       3    1  NaN      0      0    7.7500               0   \n",
       "777         0       3    1  NaN      0      0    7.7375               0   \n",
       "782         0       3    1  NaN      1      2   23.4500               1   \n",
       "789         0       3    1  NaN      0      0    7.7500               0   \n",
       "791         0       3    0  NaN      8      2   69.5500               1   \n",
       "792         0       1    1  NaN      0      0   30.6958               0   \n",
       "814         0       1    1  NaN      0      0    0.0000               1   \n",
       "824         0       3    1  NaN      0      0    6.9500               0   \n",
       "825         0       3    1  NaN      0      0   56.4958               1   \n",
       "827         1       3    1  NaN      0      0    7.7500               0   \n",
       "830         0       3    1  NaN      0      0    7.2292               0   \n",
       "835         0       3    1  NaN      0      0    8.0500               1   \n",
       "837         1       1    1  NaN      0      0   29.7000               0   \n",
       "844         0       3    1  NaN      8      2   69.5500               1   \n",
       "847         1       1    0  NaN      1      0   89.1042               0   \n",
       "857         0       3    1  NaN      0      0    7.2292               0   \n",
       "861         0       3    0  NaN      8      2   69.5500               1   \n",
       "866         0       3    1  NaN      0      0    9.5000               1   \n",
       "876         0       3    1  NaN      0      0    7.8958               1   \n",
       "886         0       3    0  NaN      1      2   23.4500               1   \n",
       "\n",
       "     is_cherbourg  \n",
       "5               0  \n",
       "17              0  \n",
       "19              1  \n",
       "26              1  \n",
       "28              0  \n",
       "29              0  \n",
       "31              1  \n",
       "32              0  \n",
       "36              1  \n",
       "42              1  \n",
       "45              0  \n",
       "46              0  \n",
       "47              0  \n",
       "48              1  \n",
       "55              0  \n",
       "63              1  \n",
       "64              1  \n",
       "75              0  \n",
       "76              0  \n",
       "81              0  \n",
       "86              0  \n",
       "94              0  \n",
       "100             0  \n",
       "106             0  \n",
       "108             0  \n",
       "120             0  \n",
       "125             0  \n",
       "127             1  \n",
       "139             1  \n",
       "153             0  \n",
       "..            ...  \n",
       "717             0  \n",
       "726             0  \n",
       "731             0  \n",
       "737             0  \n",
       "738             0  \n",
       "739             0  \n",
       "759             0  \n",
       "765             1  \n",
       "767             0  \n",
       "772             1  \n",
       "775             0  \n",
       "777             0  \n",
       "782             0  \n",
       "789             0  \n",
       "791             0  \n",
       "792             1  \n",
       "814             0  \n",
       "824             0  \n",
       "825             0  \n",
       "827             0  \n",
       "830             1  \n",
       "835             0  \n",
       "837             1  \n",
       "844             0  \n",
       "847             1  \n",
       "857             1  \n",
       "861             0  \n",
       "866             0  \n",
       "876             0  \n",
       "886             0  \n",
       "\n",
       "[177 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic_train[df_titanic_train['Age'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are more than 100 rows with no age, I am going to fill these cells in with the median age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "median = df_titanic_train['Age'].median()\n",
    "df_titanic_train['Age'] = df_titanic_train['Age'].fillna(median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create histograms to see how `Age` and `Fare` lool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAECCAYAAAASDQdFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11782dd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAECCAYAAADw0Rw8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117c65fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_titanic_train['Fare'].hist(bins = 20)\n",
    "plt.show()\n",
    "df_titanic_train['Age'].hist(bins = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Age` looks fine, but there seems to be a big skew in `Fare`. I am going to check the column to make sure there are no strange, low values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>is_southampton</th>\n",
       "      <th>is_cherbourg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex   Age  SibSp  Parch  Fare  is_southampton  \\\n",
       "178         0       3    1  36.0      0      0   0.0               1   \n",
       "262         0       1    1  40.0      0      0   0.0               1   \n",
       "270         1       3    1  25.0      0      0   0.0               1   \n",
       "276         0       2    1  28.0      0      0   0.0               1   \n",
       "301         0       3    1  19.0      0      0   0.0               1   \n",
       "412         0       2    1  28.0      0      0   0.0               1   \n",
       "465         0       2    1  28.0      0      0   0.0               1   \n",
       "480         0       2    1  28.0      0      0   0.0               1   \n",
       "596         0       3    1  49.0      0      0   0.0               1   \n",
       "632         0       1    1  28.0      0      0   0.0               1   \n",
       "673         0       2    1  28.0      0      0   0.0               1   \n",
       "731         0       2    1  28.0      0      0   0.0               1   \n",
       "805         0       1    1  39.0      0      0   0.0               1   \n",
       "814         0       1    1  28.0      0      0   0.0               1   \n",
       "821         0       1    1  38.0      0      0   0.0               1   \n",
       "\n",
       "     is_cherbourg  \n",
       "178             0  \n",
       "262             0  \n",
       "270             0  \n",
       "276             0  \n",
       "301             0  \n",
       "412             0  \n",
       "465             0  \n",
       "480             0  \n",
       "596             0  \n",
       "632             0  \n",
       "673             0  \n",
       "731             0  \n",
       "805             0  \n",
       "814             0  \n",
       "821             0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic_train[df_titanic_train['Fare'] < 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like there are quite a few cells with fares of 0. I am going to replace these numbers with the corresponding median of the fare for everyone with the same `Pclass`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>is_southampton</th>\n",
       "      <th>is_cherbourg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  is_southampton  \\\n",
       "0         0       3    1  22.0      1      0   7.2500               1   \n",
       "1         1       1    0  38.0      1      0  71.2833               0   \n",
       "2         1       3    0  26.0      0      0   7.9250               1   \n",
       "3         1       1    0  35.0      1      0  53.1000               1   \n",
       "4         0       3    1  35.0      0      0   8.0500               1   \n",
       "\n",
       "   is_cherbourg  \n",
       "0             0  \n",
       "1             1  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_one = df_titanic_train[df_titanic_train.Pclass == 1].Fare.median()\n",
    "class_two = df_titanic_train[df_titanic_train.Pclass == 2].Fare.median()\n",
    "class_three = df_titanic_train[df_titanic_train.Pclass == 3].Fare.median()\n",
    "indices = df_titanic_train[df_titanic_train['Fare'] < 1].index\n",
    "for x in indices:\n",
    "    if df_titanic_train.loc[x, 'Pclass'] == 1:\n",
    "        df_titanic_train.loc[x, 'Fare'] = class_one\n",
    "    if df_titanic_train.loc[x, 'Pclass'] == 2:\n",
    "        df_titanic_train.loc[x, 'Fare'] = class_two\n",
    "    if df_titanic_train.loc[x, 'Pclass'] == 3:\n",
    "        df_titanic_train.loc[x, 'Fare'] = class_three\n",
    "        \n",
    "df_titanic_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to create the X and y datasets and split it into training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_titan = df_titanic_train[df_titanic_train.columns.tolist()[1:]]\n",
    "y_titan = df_titanic_train['Survived']\n",
    "X_titanic_train, X_titanic_test, y_titanic_train, y_titanic_test = train_test_split(X_titan, y_titan, test_size=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am going to fit a model for this dataset. I am going to set n to 10 so the tree does not overflow too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root:  predictor: Sex | threshold: 0 | # elements: 622\n",
      "   child:  predictor: Pclass | threshold: 2 | # elements: 231\n",
      "      grandchild^1:  predictor: Age | threshold: 2.0 | # elements: 119\n",
      "         grandchild^2:  predictor: Pclass | threshold: 1 | # elements: 2\n",
      "            grandchild^3:  class of leaf: 0\n",
      "            grandchild^3:  class of leaf: 1\n",
      "         grandchild^2:  predictor: Fare | threshold: 28.7125 | # elements: 117\n",
      "            grandchild^3:  predictor: Fare | threshold: 27.75 | # elements: 53\n",
      "               grandchild^4:  predictor: Age | threshold: 55.0 | # elements: 52\n",
      "                  grandchild^5:  predictor: Age | threshold: 36.0 | # elements: 50\n",
      "                     grandchild^6:  predictor: Age | threshold: 24.0 | # elements: 36\n",
      "                        grandchild^7:  class of leaf: 1\n",
      "                        grandchild^7:  class of leaf: 1\n",
      "                     grandchild^6:  predictor: Age | threshold: 38.0 | # elements: 14\n",
      "                        grandchild^7:  class of leaf: 0\n",
      "                        grandchild^7:  class of leaf: 1\n",
      "                  grandchild^5:  predictor: Pclass | threshold: 1 | # elements: 2\n",
      "                     grandchild^6:  class of leaf: 1\n",
      "                     grandchild^6:  class of leaf: 0\n",
      "               grandchild^4:  class of leaf: 0\n",
      "            grandchild^3:  class of leaf: 1\n",
      "      grandchild^1:  predictor: Fare | threshold: 24.15 | # elements: 112\n",
      "         grandchild^2:  predictor: is_southampton | threshold: 0 | # elements: 93\n",
      "            grandchild^3:  predictor: Age | threshold: 29.0 | # elements: 46\n",
      "               grandchild^4:  predictor: Fare | threshold: 6.75 | # elements: 44\n",
      "                  grandchild^5:  class of leaf: 0\n",
      "                  grandchild^5:  predictor: Fare | threshold: 15.2458 | # elements: 43\n",
      "                     grandchild^6:  predictor: Fare | threshold: 13.4167 | # elements: 32\n",
      "                        grandchild^7:  class of leaf: 1\n",
      "                        grandchild^7:  class of leaf: 0\n",
      "                     grandchild^6:  class of leaf: 1\n",
      "               grandchild^4:  class of leaf: 0\n",
      "            grandchild^3:  predictor: Fare | threshold: 17.4 | # elements: 47\n",
      "               grandchild^4:  predictor: Fare | threshold: 10.5167 | # elements: 39\n",
      "                  grandchild^5:  predictor: Age | threshold: 26.0 | # elements: 26\n",
      "                     grandchild^6:  predictor: Fare | threshold: 7.925 | # elements: 14\n",
      "                        grandchild^7:  class of leaf: 1\n",
      "                        grandchild^7:  class of leaf: 0\n",
      "                     grandchild^6:  predictor: Age | threshold: 45.0 | # elements: 12\n",
      "                        grandchild^7:  class of leaf: 0\n",
      "                        grandchild^7:  class of leaf: 1\n",
      "                  grandchild^5:  predictor: Age | threshold: 36.0 | # elements: 13\n",
      "                     grandchild^6:  predictor: Fare | threshold: 12.475 | # elements: 12\n",
      "                        grandchild^7:  class of leaf: 1\n",
      "                        grandchild^7:  class of leaf: 1\n",
      "                     grandchild^6:  class of leaf: 0\n",
      "               grandchild^4:  predictor: Age | threshold: 4.0 | # elements: 8\n",
      "                  grandchild^5:  predictor: Age | threshold: 3.0 | # elements: 2\n",
      "                     grandchild^6:  class of leaf: 0\n",
      "                     grandchild^6:  class of leaf: 1\n",
      "                  grandchild^5:  class of leaf: 0\n",
      "         grandchild^2:  class of leaf: 0\n",
      "   child:  predictor: Age | threshold: 4.0 | # elements: 391\n",
      "      grandchild^1:  predictor: SibSp | threshold: 2 | # elements: 18\n",
      "         grandchild^2:  class of leaf: 1\n",
      "         grandchild^2:  predictor: Age | threshold: 2.0 | # elements: 7\n",
      "            grandchild^3:  class of leaf: 0\n",
      "            grandchild^3:  predictor: Age | threshold: 3.0 | # elements: 3\n",
      "               grandchild^4:  class of leaf: 1\n",
      "               grandchild^4:  class of leaf: 0\n",
      "      grandchild^1:  predictor: Pclass | threshold: 1 | # elements: 373\n",
      "         grandchild^2:  predictor: Age | threshold: 52.0 | # elements: 86\n",
      "            grandchild^3:  predictor: Fare | threshold: 35.5 | # elements: 70\n",
      "               grandchild^4:  predictor: Fare | threshold: 26.0 | # elements: 26\n",
      "                  grandchild^5:  class of leaf: 0\n",
      "                  grandchild^5:  predictor: Fare | threshold: 26.55 | # elements: 22\n",
      "                     grandchild^6:  class of leaf: 1\n",
      "                     grandchild^6:  predictor: Age | threshold: 28.0 | # elements: 16\n",
      "                        grandchild^7:  class of leaf: 1\n",
      "                        grandchild^7:  class of leaf: 0\n",
      "               grandchild^4:  predictor: SibSp | threshold: 0 | # elements: 44\n",
      "                  grandchild^5:  predictor: Age | threshold: 17.0 | # elements: 23\n",
      "                     grandchild^6:  class of leaf: 1\n",
      "                     grandchild^6:  predictor: Age | threshold: 27.0 | # elements: 22\n",
      "                        grandchild^7:  class of leaf: 0\n",
      "                        grandchild^7:  class of leaf: 0\n",
      "                  grandchild^5:  predictor: Age | threshold: 19.0 | # elements: 21\n",
      "                     grandchild^6:  predictor: Age | threshold: 11.0 | # elements: 4\n",
      "                        grandchild^7:  class of leaf: 1\n",
      "                        grandchild^7:  class of leaf: 0\n",
      "                     grandchild^6:  predictor: Age | threshold: 27.0 | # elements: 17\n",
      "                        grandchild^7:  class of leaf: 1\n",
      "                        grandchild^7:  class of leaf: 1\n",
      "            grandchild^3:  predictor: SibSp | threshold: 0 | # elements: 16\n",
      "               grandchild^4:  class of leaf: 0\n",
      "               grandchild^4:  predictor: Age | threshold: 60.0 | # elements: 3\n",
      "                  grandchild^5:  class of leaf: 1\n",
      "                  grandchild^5:  class of leaf: 0\n",
      "         grandchild^2:  predictor: Age | threshold: 9.0 | # elements: 287\n",
      "            grandchild^3:  predictor: SibSp | threshold: 1 | # elements: 8\n",
      "               grandchild^4:  class of leaf: 1\n",
      "               grandchild^4:  class of leaf: 0\n",
      "            grandchild^3:  predictor: SibSp | threshold: 1 | # elements: 279\n",
      "               grandchild^4:  predictor: Fare | threshold: 41.5792 | # elements: 262\n",
      "                  grandchild^5:  predictor: Fare | threshold: 13.8625 | # elements: 258\n",
      "                     grandchild^6:  predictor: Fare | threshold: 13.5 | # elements: 200\n",
      "                        grandchild^7:  class of leaf: 0\n",
      "                        grandchild^7:  class of leaf: 1\n",
      "                     grandchild^6:  predictor: is_cherbourg | threshold: 0 | # elements: 58\n",
      "                        grandchild^7:  class of leaf: 0\n",
      "                        grandchild^7:  class of leaf: 0\n",
      "                  grandchild^5:  predictor: Pclass | threshold: 2 | # elements: 4\n",
      "                     grandchild^6:  class of leaf: 0\n",
      "                     grandchild^6:  predictor: Age | threshold: 26.0 | # elements: 3\n",
      "                        grandchild^7:  class of leaf: 1\n",
      "                        grandchild^7:  class of leaf: 1\n",
      "               grandchild^4:  class of leaf: 0\n",
      " \n"
     ]
    }
   ],
   "source": [
    "four = Tree()\n",
    "four.fit(X_titanic_train, y_titanic_train, n=8)\n",
    "print(four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[148  20]\n",
      " [ 27  72]]\n",
      "\n",
      "Accuracy Score: \n",
      "0.823970037453\n"
     ]
    }
   ],
   "source": [
    "titanic_preds = four.predict(X_titanic_test)\n",
    "metrics(y_titanic_test, titanic_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems like a reasonable accuracy score (about 82%). However, there are about 47 misclassified points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to move on to dataset 5.\n",
    "\n",
    "### Dataset 5\n",
    "\n",
    "I read in the csv file, create X and y datasets, and split these into training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"noisy_dataset.csv\", index_col = 0)\n",
    "X_noisy = dataframe[['x_1', 'x_2']]\n",
    "y_noisy = dataframe['y']\n",
    "X_noisy_train, X_noisy_test, y_noisy_train, y_noisy_test = train_test_split(X_noisy, y_noisy, test_size=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am going to fit the model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_scores = dict()\n",
    "five = Tree()\n",
    "for x in range(3, 8):\n",
    "    five.fit(X_noisy_train, y_noisy_train, n=x)\n",
    "    noisy_preds = five.predict(X_noisy_test)\n",
    "    models_scores[x] = accuracy_score(y_noisy_test, noisy_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 0.73333333333333328,\n",
       " 4: 0.72666666666666668,\n",
       " 5: 0.7533333333333333,\n",
       " 6: 0.77000000000000002,\n",
       " 7: 0.75}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = list(models_scores.keys())\n",
    "y = list(models_scores.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAERCAYAAACO6FuTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1188d4358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y, linewidths=9)\n",
    "plt.xlabel(\"Depth of tree\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the graph, it looks like the sixth level has the best accuracy score in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to scikit-learn's `DecisionTreeClassifier` class\n",
    "\n",
    "It should come as no surprise to you that scikit-learn has a [decision tree class](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier).  Compare your constructed class to theirs in terms of their functionality, what attributes and constructor-arguments does their decision tree class have that yours does not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn's `DecisionTreeClassifier` class, when compared to ours, accepts more parameters and as a result can be more fine-tuned. Moreover, it provides more advanced functions, such as `score` and `predict_proba`. For example, according to its documentation, `score` returns the mean accuracy on the given test data and labels, and `predict_proba` predicts class probabilities of the input samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are all the parameters accepted by the `DecisionTreeClassifier` class from `sklearn`:\n",
    "\n",
    "__init__(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_split=1e-07, class_weight=None, presort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In comparison, our class only accepts the following parameters:\n",
    "* X dataframe\n",
    "* y dataframe\n",
    "* n: maximum depth (stopping condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are all the fields and methods of the class from `sklearn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dir(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting and what to do about it\n",
    "\n",
    "What we saw (hopefully!) in dataset 6 above is called __overfitting__, meaning our model is learning the noise in the training data.  This weakens the models predictive power.  There are many options to reduce overfitting, here are a few.  Implement at least one of them, until you have something that makes your models noticeably better.\n",
    "\n",
    "* Add a stopping condition: \n",
    " * stop splitting off more nodes when a node reaches either a minimal number of items per node _or_ is a pure node,\n",
    " * stop splitting by not allowing any child nodes to go below a minimum number of nodes,\n",
    " * stop splitting when you've reached some maximum depth.\n",
    "* After fitting a deep, overfit tree, use a __validation__ set to _prune_ the tree: remove nodes by rejoining children into parents, then test them against the validation set to see if the pruned tree was better.  Do this until you stop seeing improvements on the validation set.  Here a validation set means a third split of data, different from test and train.  It's different from the training set because you're not training the model on it, but it's also not testing data because you're changing your model based on knowledge gained from the dataset.  It's somewhere in between.  Feel free to ask me about _cross-validation_ as well, and how you could use that instead.  We'll talk about it eventually, but I don't want to add more to this project than is already here.\n",
    "\n",
    "__Explain to me what you did, and where it shows up in your code (for example, is it in your class definition?).__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to go with a stopping paramater that controls the depth of the tree(i.e. how many layers). Here we added an `\"n\"` value that controls the limits depth of the tree. The default value we use is 10 (1024 nodes max). It is found in the `fit` method in the Tree class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible extensions\n",
    "\n",
    "Here are two extensions of the `DecisionTree` class that you made.  They are entirely optional, so don't feel you need to do them!\n",
    "\n",
    "* In reality, people use decision trees on a limited basis, typically only when model interpretability is forced by government institutions (so, this happens a lot with banks, for example).  What you normally do is build a __forest__ of trees, that is, a collection of several trees (a common number is 50-500 trees), and then have them vote.  However, if you let your trees build themselves from the same exact datasets each time, they will be roughly the same, and the power of this voting model will be irrelevant.  Thus, one extremely common model is called the __Random Forest__ classifier: give each tree only a subset of the features to train from, don't prune at all (allow them to overfit on that subset), and then have them vote.  This increases the variance of the distribution of tree votes, which helps to average out the errors.  Create a new Python class that builds this classification model.  Note that Random Forests are a current industry favorite (among other things, like support vector machines, boosted trees, and neural networks), meaning if you do this you'll have created a model capable of hacking it with some of the best!\n",
    "\n",
    "* Scikit-learn's `DecisionTreeClassifier` has a somewhat pretty visualization of the tree that can be exported using the library `GraphViz`.  There are python wrappers to this module, the most common is `pydot`.  Using these libraries, or similar ones, add the functionality of constructing an attractive visualization of your decision tree class."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
